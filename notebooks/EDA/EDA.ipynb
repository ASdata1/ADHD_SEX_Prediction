{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e57f99",
   "metadata": {},
   "source": [
    " # EDA\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADHD Prediction Dataset - Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the preprocessed \n",
    "ADHD dataset to understand feature distributions, relationships, and data quality \n",
    "before model training.\n",
    "\n",
    "Project: ADHD Sex Prediction\n",
    "Input: Preprocessed dataset from Data Preparation module\n",
    "Output: EDA insights and visualizations for model development\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION AND SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "# Set plotting style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Figure settings\n",
    "FIGURE_SIZE = (12, 8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee382e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND INITIAL INSPECTION\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_inspect_data():\n",
    "    \"\"\"\n",
    "    Load preprocessed dataset and perform initial inspection.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Loaded and validated dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load preprocessed data\n",
    "    data_path = r\"C:\\Users\\04ama\\OneDrive\\chemistry\\ADHD_SEX_Prediction\\notebooks\\Data Preparation\\balanced_adhd_dataset.csv\"\n",
    "  \n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "       \n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ‚ùå Error: Dataset not found at {data_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error loading dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load the dataset\n",
    "df = load_and_inspect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# QUANTITATIVE FEATURES ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_quantitative_features(df):\n",
    "    \"\"\"\n",
    "    Analyze distribution and characteristics of quantitative features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset with quantitative features\n",
    "    \"\"\"\n",
    "    print(\"üìä STEP 4: Quantitative Features Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Identify quantitative columns (standardized features from preprocessing)\n",
    "    quant_cols = [col for col in df.columns if any(col.startswith(prefix) for prefix in ['APQ_', 'SDQ_', 'EHQ_', 'ColorVision'])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if quant_cols:\n",
    "        # Statistical summary\n",
    "        print(f\"\\n Statistical Summary:\")\n",
    "        summary_stats = df[quant_cols].describe()\n",
    "        print(summary_stats.round(3))\n",
    "        \n",
    "        # Check for standardization (mean ‚âà 0, std ‚âà 1)\n",
    "        means = df[quant_cols].mean()\n",
    "        stds = df[quant_cols].std()\n",
    "        \n",
    "        print(f\"\\n Standardisation Check:\")\n",
    "        print(f\"   Mean range: [{means.min():.3f}, {means.max():.3f}]\")\n",
    "        print(f\"   Std range: [{stds.min():.3f}, {stds.max():.3f}]\")\n",
    "        \n",
    "        if abs(means.mean()) < 0.1 and abs(stds.mean() - 1) < 0.1:\n",
    "            print(f\"  Features appear to be standardised\")\n",
    "        else:\n",
    "            print(f\"Features not properly standardised\")\n",
    "\n",
    "        # Distribution visualisation\n",
    "\n",
    "        n_cols = min(len(quant_cols), 20)  # Limit to first 20 for readability\n",
    "        \n",
    "        if n_cols > 0:\n",
    "            fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "            axes = axes.ravel() if n_cols > 1 else [axes]\n",
    "            \n",
    "            for i, col in enumerate(quant_cols[:n_cols]):\n",
    "                if i < len(axes):\n",
    "                    df[col].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "                    axes[i].set_title(f'{col}\\n(Œº={df[col].mean():.2f}, œÉ={df[col].std():.2f})')\n",
    "                    axes[i].tick_params(axis='x', labelsize=8)\n",
    "                    axes[i].tick_params(axis='y', labelsize=8)\n",
    "            \n",
    "            # Hide unused subplots\n",
    "            for i in range(n_cols, len(axes)):\n",
    "                axes[i].set_visible(False)\n",
    "            \n",
    "            plt.suptitle('Quantitative Features Distribution (Post-Preprocessing)', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Analyze quantitative features\n",
    "analyze_quantitative_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15305b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONNECTOME PCA COMPONENTS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_connectome_pca(df):\n",
    "    \"\"\"\n",
    "    Analyze PCA components from connectome data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset with PCA components\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Identify PCA components\n",
    "    pca_cols = [col for col in df.columns if col.startswith('conn_')]\n",
    "\n",
    "    if not pca_cols:\n",
    "        print(\"   No PCA components found with 'conn_' prefix\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Found {len(pca_cols)} PCA components from connectome data\")\n",
    "    \n",
    "    # Statistical summary of PCA components\n",
    "    print(f\"\\n PCA Components Summary:\")\n",
    "    pca_summary = df[pca_cols].describe()\n",
    "    print(pca_summary.round(3))\n",
    "    \n",
    "    # Visualization of first few components\n",
    "    if len(pca_cols) >= 2:\n",
    "    \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        # Scatter plot of first two components\n",
    "        scatter = axes[0].scatter(df[pca_cols[0]], df[pca_cols[1]],\n",
    "                                   c=df['ADHD_Outcome'], alpha=0.6, cmap='viridis')\n",
    "        axes[0].set_xlabel(f'{pca_cols[0]}')\n",
    "        axes[0].set_ylabel(f'{pca_cols[1]}')\n",
    "        axes[0].set_title('First Two PCA Components (Colored by ADHD Outcome)')\n",
    "        plt.colorbar(scatter, ax=axes[0])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Correlation matrix of first 5 components\n",
    "        n_components = min(5, len(pca_cols))\n",
    "        corr_matrix = df[pca_cols[:n_components]].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                   ax=axes[1], square=True)\n",
    "        axes[1].set_title(f'Correlation Matrix: First {n_components} PCA Components')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Component importance (variance analysis if available)\n",
    "    print(f\"\\n PCA Component Statistics:\")\n",
    "    for i, col in enumerate(pca_cols[:11]):  # Show first 5\n",
    "        variance = df[col].var()\n",
    "        print(f\" {col}: Variance = {variance:.4f}\")\n",
    "\n",
    "# Analyze connectome PCA components  \n",
    "analyze_connectome_pca(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CATEGORICAL FEATURES ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_categorical_features(df):\n",
    "    \"\"\"\n",
    "    Analyze encoded categorical features and their relationships with target.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataset with encoded categorical features\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Identify encoded categorical columns\n",
    "    cat_encoded_cols = [col for col in df.columns if any(col.startswith(prefix) \n",
    "                       for prefix in ['PreInt_', 'Basic_', 'Sex_', 'Barratt_',])]\n",
    "    \n",
    "  \n",
    "    \n",
    "    print(f\"{len(cat_encoded_cols)} encoded categorical features\")\n",
    "    \n",
    "    # Group by original categorical variable\n",
    "    categorical_groups = {}\n",
    "    for col in cat_encoded_cols:\n",
    "        prefix = col.split('_')[0] + '_'\n",
    "        if prefix not in categorical_groups:\n",
    "            categorical_groups[prefix] = []\n",
    "        categorical_groups[prefix].append(col)\n",
    "    \n",
    "    print(f\"\\n Categorical Variable Groups:\")\n",
    "    for group, cols in categorical_groups.items():\n",
    "        print(f\"{group[:-1]}: {len(cols)} categories\")\n",
    "    \n",
    "    # Analyze relationship with target variable\n",
    "    if 'ADHD_Outcome' in df.columns:\n",
    "        print(f\"\\n Categorical Features vs ADHD Outcome:\")\n",
    "        \n",
    "        # Focus on key categorical variables\n",
    "        key_groups = list(categorical_groups.keys())[:4]  # Analyze first 4 groups\n",
    "        \n",
    "        if key_groups:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            axes = axes.ravel()\n",
    "            \n",
    "            for i, group in enumerate(key_groups):\n",
    "                if i < len(axes):\n",
    "                    # Create a summary variable for this group (most common category)\n",
    "                    group_cols = categorical_groups[group]\n",
    "                    \n",
    "                    # Find the active category for each sample\n",
    "                    group_data = df[group_cols].copy()\n",
    "                    active_categories = []\n",
    "                    \n",
    "                    for idx in range(len(df)):\n",
    "                        active_cols = group_data.iloc[idx][group_data.iloc[idx] == 1].index.tolist()\n",
    "                        if active_cols:\n",
    "                            active_categories.append(active_cols[0].replace(group, ''))\n",
    "                        else:\n",
    "                            active_categories.append('Unknown')\n",
    "                    \n",
    "                    # Create temporary dataframe for plotting\n",
    "                    temp_df = pd.DataFrame({\n",
    "                        'category': active_categories,\n",
    "                        'ADHD_Outcome': df['ADHD_Outcome']\n",
    "                    })\n",
    "                    \n",
    "                    # Count plot\n",
    "                    sns.countplot(data=temp_df, x='category', hue='ADHD_Outcome', ax=axes[i])\n",
    "                    axes[i].set_title(f'{group[:-1]} Distribution by ADHD Outcome')\n",
    "                    axes[i].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "  \n",
    "# Analyze categorical features\n",
    "analyze_categorical_features(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
