{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72a7e9f",
   "metadata": {},
   "source": [
    "## Testing Baseline ML Models witha big loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01646bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADHD Prediction Dataset - Baseline Models Evaluation\n",
    "\n",
    "This notebook implements and evaluates baseline machine learning models for ADHD prediction\n",
    "to establish performance benchmarks before advanced feature engineering and model optimization.\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: [Date]\n",
    "Project: ADHD Sex Prediction\n",
    "Input: Baseline dataset (minimal preprocessing)\n",
    "Output: Baseline model performance metrics and comparison\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                           f1_score, precision_score, recall_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION AND SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64029fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND INITIAL EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_explore_baseline_data():\n",
    "    \"\"\"\n",
    "    Load baseline dataset and perform initial exploration.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (X, y, df) - Feature matrix, target vector, and full dataframe\n",
    "    \"\"\"\n",
    " \n",
    "    \n",
    "    # Load baseline dataset\n",
    "    data_path = r\"C:\\Users\\04ama\\OneDrive\\chemistry\\ADHD_SEX_Prediction\\notebooks\\Feature Engineering\\final_dataset.csv\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        print(f\"  Dataset loaded successfully\")\n",
    "        print(f\"  Dataset shape: {df.shape}\")\n",
    "        \n",
    "        # Display target distribution\n",
    "        target_counts = df['ADHD_Outcome'].value_counts()\n",
    "        target_props = df['ADHD_Outcome'].value_counts(normalize=True)\n",
    "        \n",
    "        for label in sorted(df['ADHD_Outcome'].unique()):\n",
    "            count = target_counts[label]\n",
    "            prop = target_props[label]\n",
    "            print(f\" Class {label}: {count:,} samples ({prop:.1%})\")\n",
    "        \n",
    "        # Prepare features and target\n",
    "        target_col = 'ADHD_Outcome'\n",
    "        X = df.drop(columns=[target_col, 'participant_id'], errors='ignore')\n",
    "        y = df[target_col]\n",
    "        \n",
    "        print(f\" Features shape: {X.shape}\")\n",
    "        print(f\" Target shape: {y.shape}\")\n",
    "    \n",
    "        # Check for missing values\n",
    "        missing_counts = X.isnull().sum()\n",
    "        if missing_counts.sum() > 0:\n",
    "            print(f\" Missing values detected:\")\n",
    "            missing_features = missing_counts[missing_counts > 0]\n",
    "            for feature, count in missing_features.items():\n",
    "                print(f\"      • {feature}: {count} missing\")\n",
    "        else:\n",
    "            print(f\"   No missing values detected\")\n",
    "        \n",
    "        return X, y, df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Error: Dataset not found at {data_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error loading dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# ✅ FIXED: Call the function OUTSIDE the function definition\n",
    "X, y, df = load_and_explore_baseline_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2aa7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA SPLITTING STRATEGY\n",
    "# =============================================================================\n",
    "\n",
    "def create_baseline_splits(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Create train/test splits for baseline model evaluation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Target vector\n",
    "    test_size : float\n",
    "        Proportion for test set\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create stratified train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    # Verify stratification\n",
    "    print(f\" Stratification Verification:\")\n",
    "    train_dist = y_train.value_counts(normalize=True).sort_index()\n",
    "    test_dist = y_test.value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    print(f\"  Training distribution: {dict(train_dist.round(3))}\")\n",
    "    print(f\"  Test distribution: {dict(test_dist.round(3))}\")\n",
    "\n",
    "    # Check if distributions are similar\n",
    "    max_diff = abs(train_dist - test_dist).max()\n",
    "    if max_diff < 0.05:\n",
    "        print(f\"  Stratification successful (max difference: {max_diff:.3f})\")\n",
    "    else:\n",
    "        print(f\"  Stratification concern (max difference: {max_diff:.3f})\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Create data splits\n",
    "X_train, X_test, y_train, y_test = create_baseline_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf49845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BASELINE MODELS DEFINITION AND TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "def define_baseline_models():\n",
    "    \"\"\"\n",
    "    Define baseline machine learning models for comparison.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of model names and initialized models\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            random_state=RANDOM_STATE, \n",
    "            max_iter=1000,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            random_state=RANDOM_STATE, \n",
    "            n_estimators=100,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'SVM': SVC(\n",
    "            random_state=RANDOM_STATE, \n",
    "            probability=True,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'LightGBM': lgb.LGBMClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            class_weight='balanced',\n",
    "            verbose=-1  # Suppress training output\n",
    "        ),\n",
    "        'XGBoost': xgb.XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            eval_metric='logloss',\n",
    "            verbosity=0  # Suppress training output\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    return models\n",
    "\n",
    "def train_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and evaluate all baseline models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : dict\n",
    "        Dictionary of model names and initialized models\n",
    "    X_train, X_test : pd.DataFrame\n",
    "        Training and test feature matrices\n",
    "    y_train, y_test : pd.Series\n",
    "        Training and test target vectors\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Comprehensive results for all models\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i, (name, model) in enumerate(models.items(), 1):\n",
    "       \n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Calculate comprehensive metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='binary')\n",
    "        recall = recall_score(y_test, y_pred, average='binary')\n",
    "        f1_binary = f1_score(y_test, y_pred, average='binary')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_binary': f1_binary,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_proba\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\" {model}      Performance Metrics:\")\n",
    "        print(f\"          Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"         Precision: {precision:.4f}\")\n",
    "        print(f\"         Recall: {recall:.4f}\")\n",
    "        print(f\"         F1-Binary: {f1_binary:.4f}\")\n",
    "        print(f\"         F1-Macro: {f1_macro:.4f}\")\n",
    "        print(f\"         F1-Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "    \n",
    "       \n",
    "   \n",
    "        # Confusion matrix\n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "       \n",
    "        \n",
    "        # Create confusion matrix visualization\n",
    "        create_confusion_matrix_plot(cm, name, y_test, y_pred)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_confusion_matrix_plot(cm, model_name, y_true, y_pred):\n",
    "    \"\"\"Create and display confusion matrix plot.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['No ADHD', 'ADHD'], \n",
    "                yticklabels=['No ADHD', 'ADHD'])\n",
    "    plt.title(f'{model_name} - Confusion Matrix\\nAccuracy: {accuracy_score(y_true, y_pred):.3f}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define and train models\n",
    "models = define_baseline_models()\n",
    "results = train_and_evaluate_models(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6666a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
